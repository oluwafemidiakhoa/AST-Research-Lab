{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ AST Competition Starter - Train Faster, Save GPU Hours\n",
    "\n",
    "**Adaptive Sparse Training** automatically selects the most important training samples, achieving:\n",
    "- ‚ö° **60-70% energy savings** (train faster, use less GPU time)\n",
    "- üéØ **Same or better accuracy** (curriculum learning effect)\n",
    "- üí∞ **Lower costs** (less compute = lower Kaggle/Colab costs)\n",
    "\n",
    "This notebook is a **drop-in replacement** for standard training loops.\n",
    "\n",
    "---\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install adaptive-sparse-training -q\n",
    "!pip install timm -q  # For advanced models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup: Load Your Data\n",
    "\n",
    "Replace this with your competition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from adaptive_sparse_training import AdaptiveSparseTrainer, ASTConfig\n",
    "\n",
    "# Example: Image classification dataset\n",
    "# TODO: Replace with your competition data\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load your training data\n",
    "train_dataset = torchvision.datasets.ImageFolder('/kaggle/input/your-data/train', transform=transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder('/kaggle/input/your-data/val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(f\"üìä Dataset: {len(train_dataset)} train, {len(val_dataset)} val, {num_classes} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Model Selection\n",
    "\n",
    "Choose any model from [timm](https://github.com/huggingface/pytorch-image-models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular choices for competitions:\n",
    "# - 'efficientnet_b0' (fast, accurate)\n",
    "# - 'resnet50' (reliable baseline)\n",
    "# - 'convnext_base' (state-of-the-art)\n",
    "# - 'swin_base_patch4_window7_224' (transformer)\n",
    "\n",
    "model = timm.create_model(\n",
    "    'efficientnet_b0',\n",
    "    pretrained=True,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"üîß Model: {model.__class__.__name__} on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ AST Configuration\n",
    "\n",
    "**Key parameter:** `target_activation_rate`\n",
    "- `0.40` = 60% energy savings (recommended start)\n",
    "- `0.25` = 75% energy savings (aggressive)\n",
    "- `0.50` = 50% energy savings (conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ASTConfig(\n",
    "    target_activation_rate=0.35,  # 65% energy savings\n",
    "    entropy_weight=1.0,           # Balance loss + entropy\n",
    "    kp=0.1,                       # PI controller proportional gain\n",
    "    ki=0.01,                      # PI controller integral gain\n",
    "    use_mixed_precision=True,     # AMP for extra speedup\n",
    "    min_active_samples=8,         # Safety: never skip entire batch\n",
    ")\n",
    "\n",
    "print(\"‚öôÔ∏è  AST Config:\")\n",
    "print(f\"   Target Activation: {config.target_activation_rate:.0%}\")\n",
    "print(f\"   Expected Savings: ~{(1-config.target_activation_rate)*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Training with Live Dashboard\n",
    "\n",
    "AST automatically tracks energy, cost, and CO2 savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Custom optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "trainer = AdaptiveSparseTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    config=config,\n",
    "    optimizer=optimizer,  # Optional: uses Adam by default\n",
    ")\n",
    "\n",
    "# Train with warmup (recommended for stability)\n",
    "results = trainer.train(\n",
    "    epochs=50,\n",
    "    warmup_epochs=5  # First 5 epochs: train on 100% samples\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÅ TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üéØ Best Accuracy: {results['best_accuracy']:.2%}\")\n",
    "print(f\"‚ö° Energy Savings: {results['energy_savings']:.1%}\")\n",
    "print(f\"‚è±Ô∏è  Total Time: {results['training_time_hours']:.1f}h\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Save Model & Submit\n",
    "\n",
    "Save the trained model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'results': results,\n",
    "    'config': config,\n",
    "}, 'ast_model.pth')\n",
    "\n",
    "print(\"üíæ Model saved to ast_model.pth\")\n",
    "print(f\"üìà Trained with {results['energy_savings']:.0%} less energy than standard training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Inference (Competition Submission)\n",
    "\n",
    "Standard PyTorch inference - no AST needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model for inference\n",
    "checkpoint = torch.load('ast_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Make predictions\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Create submission\n",
    "import pandas as pd\n",
    "submission = pd.DataFrame({\n",
    "    'id': range(len(predictions)),\n",
    "    'label': predictions\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"üì§ Submission ready: submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Tips for Competition Success\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "- **Start conservative**: `target_activation_rate=0.40` (60% savings)\n",
    "- **Monitor activation rate**: Should stabilize near target after warmup\n",
    "- **If accuracy drops**: Increase `target_activation_rate` to 0.50 or add more warmup epochs\n",
    "\n",
    "### When to Use AST\n",
    "‚úÖ **Good for:**\n",
    "- Large datasets (>50k samples)\n",
    "- Limited GPU time (Kaggle 30h/week limit)\n",
    "- Image classification, object detection\n",
    "- When you need to try multiple models quickly\n",
    "\n",
    "‚ùå **Skip AST if:**\n",
    "- Tiny datasets (<5k samples)\n",
    "- Already at hardware limits (reduce batch size instead)\n",
    "\n",
    "### Advanced: Architecture Selection\n",
    "AST works best with:\n",
    "- **ResNets, EfficientNets**: Stable, predictable\n",
    "- **ConvNeXt**: Excellent with AST (tested)\n",
    "- **Vision Transformers**: May need higher `target_activation_rate` (0.50+)\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- üì¶ [PyPI Package](https://pypi.org/project/adaptive-sparse-training/)\n",
    "- üêô [GitHub Repo](https://github.com/oluwafemidiakhoa/adaptive-sparse-training)\n",
    "- üìñ [Documentation](https://github.com/oluwafemidiakhoa/adaptive-sparse-training#readme)\n",
    "\n",
    "**Questions?** Open an issue on GitHub!\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook uses Adaptive Sparse Training to reduce energy consumption by ~65% while maintaining accuracy. Good for the planet üåç and your GPU budget üí∞*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
